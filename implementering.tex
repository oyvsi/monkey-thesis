\section{Implementering}
\subsection{Utstyr}
\subsubsection{Labmiljø}
Et labmiljø har vært brukt for å teste plugins og script før de blir implementert på produksjonsserveren. Ved å teste i lab først, kan en se hvordan sjekker oppfører seg før de implementeres i større skala i produksjon. Labmiljøet inneholder utstyr og tjenester som gjenspeiler det IKT-avdelingen benytter, og på den måten kan ulike scenarier og utstyr testes før dette settes i produksjon.

I Tabell \ref{labmiljo} er en oversikt over utstyret i labmiljøet.
\begin{changemargin}{-1cm}{-1cm}
\begin{table}
\begin{center}
%\begin{tabular}{|p{2.0in}|c|c|c|} \hline
\begin{tabular}{ | l | l | l | p{4cm} |} \hline
	\textbf{Type} & \textbf{Beskrivelse} & \textbf{Dato installert} & \textbf{Tjenester} \\ \hline
	Server & Debian linux (HiG1) & 22.01.2013 & Icinga, Icinga-Web, Icinga-mobile, MySQL, Apache \\ \hline
	Server & Debian linux (HiG2) & 22.01.2013 &	MySQL, Apache \\ \hline
	Server & Windows 2008 R2 (HiG3) & 22.01.2013 & DNS, DHCP, AD, IIS, Fileserver, MSSQL \\ \hline
	Server & Windows 2008 R2 (HiG4) & 19.02.2013 & Exchange \\ \hline 
	Switch & Cisco 3550 (hig-sw1) &	29.01.2013 & SNMP \\ \hline
	Switch & Dell Powerconnect 5324 (hig-sw2) & 29.01.2013 & SNMP \\ \hline
	Router & Cisco 2600 (hig-ro) & 05.02.2013 & SNMP \\ \hline 
	Firewall & Cisco 515E (hig-fw) & 05.02.2013 & SNMP \\ \hline
\end{tabular}
\caption{Labmiljø}
\label{labmiljo}
\end{center}
\end{table}
\end{changemargin}
Serverne er virtuelle maskiner plassert i et eget VLAN som er tilgjengelig på fysiske porter slik at nettverksutstyret kan plasseres i samme subnett. VLAN-et har også tilgang ut mot internett og har vært tilgjengelig for gruppen over VPN. Tjenester som testes på HiG1, HiG2, HiG3 og HiG4 blir alle overvåkt via NRPE. For nettverksutstyret blir SNMP benyttet.

I Figur \ref{laboppsett} vises det logiske oppsettet av labmiljøet og hvilke tjenester som kjører. Hig-fw, Hig-sw1 og Hig-sw2 er koblet i serie for å teste avhengigheter og følgefeil.

\subsubsection{Produksjonsserveren}
Spesifikasjonene på bladeserveren:
\begin{itemize}
\item 4 CPU-er med 4 kjerner a x.x GHz
\item 32 GB RAM
\item Debian 6
\end{itemize}
Programvare:
\begin{itemize}
\item Debian 6
\item Apache2
\item MySQL
\item Icinga 1.8.4
\item SNMPtrapd
\item SNMPtt
\item Graphite
\item Metricinga 
\item sendmail
\end{itemize}
\subsubsection{Enhet for overvåkning av servermiljø}
For å overvåke temperatur og luftfuktighet på serverrommet ble det kjøpt inn en NetBotz 200 med støtte for opp til 12 eksterne sensorer /ref http://www.apc.com/resource/include/techspec\_index.cfm?base\_sku=NBRK0201\&tab=software,
som oppfyller kravene gitt i oppgavebeskrivelsen. 

\subsection{Overvåkning med Icinga}
\subsubsection{Produksjonsserver}
“Quis custodiet ipsos custodes?” er et latinsk uttrykk som kan oversettes med “hvem passer på de som passer på?”. I en overvåkningsløsning er det viktig å stille spørsmålet; hva skjer hvis overvåkningsserveren går ned? Et forslag under prosjektet var å legge overvåkingsserveren på et Xen/Vmware-cluster. Men dette ble etter noe omtanke stemplet som en dårlig ide. Dersom clusteret gikk ned ville også overvåkingsserveren gå ned. Det ble derfor bestemt at denne skulle være en egen fysisk boks. 

For å sikre tilgjengeligheten til Icinga ytterligere, er det også mulig å sette opp et redundant oppsett der alle Icinga-installasjoner kan dele resultater av sjekker mellom seg. Ekstra viktig vil et slikt oppsett være dersom man knytter overvåkningssystemet mot SLA-er. Dersom en mister data om oppetid og tilgjenglighet på en tjeneste, vil man ikke lenger kunne vise hva den har vært.

En annen utfordring var å vite hvor kraftig hardware serveren trengte. Her ble referanselisten til Icinga lagt til grunn(https://www.icinga.org/users/), hvor mange organisasjoner har lagt inn informasjon om sine oppsett. Etter avtale med oppgragsgiver ble det bestemt å sette opp en bladeserver, som eventuelt kunne byttes med noe kraftigere dersom det skulle bli nødvendig. 

\subsubsection{Installasjon}
I pakkebrønnen for debian-stable fantes bare versjon 1.0.2 av Icinga, i backports lå 1.7.1. Icinga opprettholder en egen pakkebrønn - “The Debian Monitoring Prosject” /ref http://debmon.org/. Fra denne kunne versjon 1.8.4 installeres. I samråd med teknisk kontakt ved IKT-avdelingen ble det bestemt å bruke versjon 1.8.4 fra debmon.

\subsubsection{Konfigurasjonsfiler}
Ved standard installasjon av Icinga er konfigurasjonen delt opp i objekttyper med flere objekter i hver fil:
\begin{itemize}
\item contacts\_icinga.cfg  
\item generic-host\_icinga.cfg     
\item hostgroups\_icinga.cfg  
\item localhost\_icinga.cfg  
\item timeperiods\_icinga.cfg
\item extinfo\_icinga.cfg   
\item generic-service\_icinga.cfg   
\item services\_icinga.cfg
\item commands.cfg
\end{itemize}
Dette var uoversiktelig og en oppdelt konfigurasjon var ønskelig, som også er anbefalt ved større installasjoner.. /cite http://www.standalone-sysadmin.com/blog/2009/07/nagios-config/ + nagios-boka. Det ble bestemt å sette opp følgdende hovedinndeling, med undermapper videre der det var hensiktsmessig:

% NILS, WTF TO DO?
%\begin{lstlisting}
%├── objects
%│   ├── commands
%│   │   ├── firewalls
%│   │   ├── servers
%│   │   ├── snmp.cfg
%│   │   └── switches
%│   ├── contactgroups
%│   ├── contacts
%│   ├── escalations
%│   ├── generics
%│   ├── hostdependencies
%│   ├── hostgroups
%│   ├── hosts
%│   ├── modules
%│   ├── servicedependencies
%│   ├── services
%\end{lstlisting}
Det ble testet ut et par verktøy for å administrere konfigurasjonsfilene NConf /ref http://www.nconf.org og NagiosQL /ref http://www.nagiosql.org. Disse ble valgt bort til fordel for manuel konfigurering da det ikke støttet oppdeling av konfigurasjon og kunne ikke kombineres med manuell konfigurasjon. I samråd med oppdragsgiver ble det avgjort av manuell konfigurasjon oppfyller kravet “Det skal være enkelt å legge til nye enheter for overvåking”.

\subsubsection{Bruk av hostgroup}
Som nevnt i /ref{der vi snakker om det} knyttes et service-objekt til et host-objekt og et command-objekt for at det skal kjøres en sjekk. For å slippe å skrive et service-objekt for hvert host-objekt benyttes gruppering av host-objekter i hostgroup. For å vise hvordan dette er satt opp vises et eksempel for hvordan dette er satt opp for MySQL-servere:

\begin{lstlisting}
define hostgroup {
        hostgroup_name mysql_servers
        alias MySQL Servers
}
\end{lstlisting}
Dette vil si at alle hosts som er medlem i hostgroupen vil få utført sjekkene som er definerert i servicen. For å legge til en host i denne gruppen kan hosten være definert på følgende måte.

\begin{lstlisting}
define host {
use		generic_windows_host
address	10.60.0.21
host_name	HiG2
alias		HiG2
hostgroups	debian_servers, mysql_servers
}
\end{lstlisting}
For å legge alle SQL serverne i en felles gruppe er det laget en egen SQL\_Servers host group. Dette gjøres for å gruppere alle SQL serverne uavhengig av hvilken database type som brukes. 

\begin{lstlisting}
define hostgroup {
hostgroup_name sql_servers
alias SQL Servers
hostgroup_members mysql_servers, mssql_servers, oracle_servers
}
\end{lstlisting}
Da kommandoene er definert lages servicen som som binder SQL serverens hostgroup og kommandoen.

\begin{lstlisting}
define service {
service_description MySQL Connection Time
use generic-service
name mysql_connection_time
hostgroup_name mysql-servers
check_command check_mysql_health!connection-time!0.1!0.4
}
\end{lstlisting}

Figur ref{sql} viser en visuel fremstilling av hvordan alt dette henger sammen for alle SQL-servere:

\subsubsection{Grafing}
I utgangspunktet ble det bestemt at grafing og trenddata skulle holdes utenfor oppgaven. Det ble likevel satt opp grafing via programmet graphite for å motta ytelsesdata og grafe dette. Dette fordi det var ønskelig å kunne etablere en baseline for tjenestene slik at bedre grenseverdier kunne settes.

For å gjøre dette benyttes et vanlig command-objekt i Icinga. Dette defineres på vanlig vis slik:

\begin{lstlisting}
define command {
command_name            rotate_perf_service
    command_line            /bin/mv /usr/local/icinga/var/perfdata/service-perfdata /usr/local/icinga/var/perfdata/logs/service-perfdata.$TIMET$
}
\end{lstlisting}
Videre må denne konfigureres i Icinga.cfg:

\begin{lstlisting}
process_performance_data=1
service_perfdata_file=/usr/local/icinga/var/perfdata/service-perfdata
service_perfdata_file_processing_command=rotate_perf_service
service_perfdata_file_template=[SERVICEPERFDATA]\tDATATYPE::SERVICEPERFDATA\tTIMET::$TIMET$\tHOSTNAME::$HOSTNAME$\tSERVICEDESC::$SERVICEDESC$\tSERVICEPERFDATA::$SERVICEPERFDATA$service_perfdata_file_processing_interval=200
\end{lstlisting}

For å transformere performance-dataen til riktig format for graphite benyttes metricinga (ref https://github.com/jgoldschrafe/metricinga). Dette scriptet sjekker spool-mappen én gang i minuttet etter filer som enda ikke er prosessert og sender data inn til carbon (graphite). 
Gjennom graphite vil det dermed grafes basert på performance data på riktig format fra alle service-checks som kjører en command.

Det ble også testet å modifisere scriptet til å legge outputen til service-sjekkene direkte til en mysql-database, som vist i vedlegg /ref{metricinga diff}. Dette ble gjort for å oppfylle kravet fra oppgavebeskrivelsen om at alle henvendelser skal lagres i database. Men det viste seg at dette ville bli så mange rader at dette ble avgjort til ikke å være hensiktsmessig i samråd med oppdragsgiver. Som et alternativ til dette kan en ta inn all data til graphite, men aggrigere det etter en viss tid. Dataen kan så eksporteres fra graphite.

\subsubsection{Overvåkning av Windows-servere}
For overvåkning av Windows vil NSClient++ bli brukt. NSClient++ er et program som brukes for  å kommunisere med ulike agenter og over ulike protokoller på en ekstern server. I dette prosjektet brukes den for å hente ut informasjon via NRPE-agenten og å kjøre WMI-spørringer mot en Windows-server. NSClient har en konfig fil som genereres under installering. 

NSClient++ er valgt fordi klienten oppdateres hyppig /cite{http://www.nsclient.org/nscp/downloads}, og det er den agenten som blir referert i Icinga/Nagios dokumentasjon /cite{http://docs.icinga.org/latest/en/monitoring-windows.html}. Med NSClient++ kommer også forhåndskonfigurerte plugin-er, for eksempel for å sjekke minne, CPU, og harddisk.

For installering av NRPE-agenten og mulighet for WMI-spørringer ble det laget en veiledning /cite{nsclientguide} som forklarer hva som skal installeres. Her er det laget en egen konfig fil som har kun funksjonaliteten vi trenger. 

\subsubsection{Overvåkning av Linux-servere}
Overvåkning av standard Linux-servere skjer utelukkende ved bruk av NRPE. 

For Debian-servere kan denne installers fra pakkebrønnen “stable” med kommandoen:

apt-get install nagios-nrpe-server nagios-plugins-basic

For Red Hat og CentOS må det benyttes en tredjeparts “pakketing” som EPEL eller DAG før nrpe-server kan installeres med yum.

Konfigurasjonen er lik som ved Windows. Det følger ikke med noen plugin-er når en installerer nagios-nrpe-server, derfor installeres også pakken “nagios-plugins-basic”.

\subsubsection{Utrulling av agenter}
NSclient++ kan lastes ned som en MSI-pakke, som kan pushes til servere med en GPO. Konfigurasjonsfilen må enten legges inn i MSI-pakken eller pushes over GPO for seg selv. Grunnen til dett ikke er benyttet er at IKT-avdelingen ønsket å gjøre installasjonen manuelt for å ha mest mulig kontroll og gjøre utrulling i faser, for å sikre at installasjonen ikke medførte uforutsette probemer. Det ble laget en veiledning på hvordan denne klienten skal installeres, og hvilke opsjoner som er relevant. Denne finnes i vedlegg \ref{nsclient++}.

For Linux servere installeres pakkene via pakkebehandleren, som nevnt i xx. IKT-avdelingen har for tiden ikke så mange Linux-servere, så noen automatisk utrulling vil ikke være så besparende. Dersom dette skulle være ønskelig kan et enkelt script som kobler seg til og kjører kommandoen for installering skrives. Konfigurasjonsfilen kan pushes over SCP.

For annen infrastruktur brukes for det meste SNMP for å hente ut informasjon. Dette konfigureres på hver enkelt enhet, og krever vanligvis ikke noe ekstra programvare installert. I noen spesielle tilfeller brukes egne API-er for å hente ut informasjon, som for eksempel for VMware. Her må Icinga serveren ha tilgang til å bruke API-et, som vanligvis konfigureres på hosten.

\subsubsection{Lokale ressurser}
For både Linux- og Windows-servere er det satt opp noen grunnsjekker som skal kjøres på alle servere. Dette er CPU-last, harddiskplass og minnebruk. Hver sjekk er definert i et service-objekt der hostgroup-ene er satt til “windows\_servers” og “linux\_servers”. 

For alle disse sjekkene er det mulig å anngi grenseverdier både som prosentandel og absolutte tall og sjekke mot både andel ledig eller andel brukt. 
\paragraph{Disk}
Lav diskplass kan skape problemer for applikasjoner som lagrer data, logging kan stoppe, og ved høyt minneforbruk og bruk av virtuelt minne vil ikke diskplass kunne utnyttes og applikasjoner kan stoppe å fungere.

Linux:

For å sjekke ledig plass på harddisken benyttes Nagios-sjekken “Check\_disk”. 
Check\_Disk
\begin{lstlisting}
./check_disk -w 8% -c 4% -e
\end{lstlisting}
Svar: 
\begin{lstlisting}
DISK OK| /=1232MB;15430;17359;0;19288 /lib/init/rw=0MB;402;452;0;503 /dev=0MB;394;443;0;493 /dev/shm=0MB;402;452;0;503
\end{lstlisting}
I sjekken over brukes oppsjoner slik at det gir en advarsel om det er 8 \% ledig diskplass, og vil gi kritisk varsel dersom det er 4 \% ledig diskplass.

For windows servere med mange disker brukes oppsjonen -CHECKALL som gir en oversikt over alle diskene på serveren. Her brukes samme opsjoner for advarsler og kristiske varsler.

-CheckDisk fra nsclient++

\paragraph{CPU}

Overvåkning av CPU vil kunne hjelpe til med å indikere problem som ressursproblemer, flere CPU-krevende applikasjoner på samme server eller at en applikasjon bruker all CPU-kraft.  
http://www.microsoft.com/en-us/download/details.aspx?id=9296


På Windows-servere benyttes “CheckCPU” fra NSClient++ for å sjekke CPU-last. Her legges det ved tre opsjoner i sjekken som spesifiserer tidsintervallet for datagrunnlaget, grensen for når det skal gis en advarsel og når det skal vises som en kritisk feil.

Check\_CPU
\begin{lstlisting}
./check_nrpe -u -H 10.60.0.22 -p 5666 -c CheckCPU -a time=5m warn=80 crit=90
\end{lstlisting}
I Figur /ref{CPUSTRAIN} returnerer CPU-sjekken “OK”. Dette er hentet fra gjennomsnittsbruk av CPU over 5 minutter. Like under ser vi at testen er kritisk på grunn av et gjennomsnittsbruk av CPU på 96 \%. I Figur /ref{CPUSTRAIN} ser vi at alle de fire CPU-kjernene jobber oppmot maksimalt. Et batch-script ble kjørt lokalt på serveren som ble overvåket for å generere CPU-bruk.
\begin{lstlisting}
# winloop.bat
@echo off
for /l %%x in (1, 1, 10) do (
    start loop.bat
)

# loop.bat
@echo off
:loop
GOTO loop
\end{lstlisting}
For Linux baserer sjekk av CPU-bruk seg på “load” /ref http://www.linuxjournal.com/article/9001
\ref http://en.wikipedia.org/wiki/Load\_(computing). Dette er i hovedsak et gjennomsnitt for hvor mange prosesser som bruker eller venter på CPU, men disk- eller nettverks I/O kan også spille inn. For maskiner med flere kjerner og/eller CPU-er vil dette fortone seg annerledes da en kan utføre flere prosesser parallellt. Load-tallene må deles på antallet CPU-kjerner for at det skal kunne brukes samme grenseverdier uavhengig av hvor mange kjerner serveren har. Dette gjøres med opsjonen “r”.

Tallene som hentes ut er gjennomsnittet for de siste 1, 5 og 15 minuttene. Det er mer interessant hvis load-en er høy over lengre tid, derfor er grenseverdiene lavere for 5 og 15 minutters intervallene.

check\_load fra nagios-plugins:
\begin{lstlisting}
load average: 0.65 0.42 0.36

check_command                   check_nrpe!check_dist_load!0.9,0.7,0.5 1.2,1.0,0.9

command[check_dist_load]=/usr/lib/nagios/plugins/check_load -r -w $ARG1$ -c $ARG2$
\end{lstlisting}

\paragraph{Minne}
Datamaskiner som bruker opp tilgjengelig minne må skrive til disk for å få plass til mellomlagrede data. Data som må hentes fra disk vil ha en betydelig høyere aksesstid enn når fysisk minne brukes til mellomlagring /cite{http://en.wikipedia.org/wiki/Paging#Performance}. 
Kontinuerlig høyt minneforbruk kan være en indikasjon på flere minnekrevende applikasjoner på samme server, en applikasjon har minnelekkasje, eller at mengden minne ikke strekker til.

Hva en prosess kan kreve. Virtuelt minne teknologi. CheckMem fra NSClient++

\begin{lstlisting}
Check_Memory
./check_nrpe -u -H 10.60.0.22 -p 5666 -c CheckMem -a MaxWarnUsed=80% MaxCritUsed=90% type=physical

Svar
OK memory within bounds.|'physical memory %'=16%;80;90 'physical memory'=1G;4;5;0;6
\end{lstlisting}

Opsjoner sendes med som gjør at sjekken gir warning når mer enn 80 \% av fysisk minne er brukt, når minneforbruket overstiger 90 \% blir minneforbruket kritisk.

For Linux benyttes plugin: https://raw.github.com/jasonhancock/nagios-memory/master/plugins/check\_mem

\subsubsection{Tjenester}
IKT-avdelingen ønsket å overvåke tjenester og prosesser på serverne. Prossesser er instanser av programmer som kjører. Tjenester er prosesser som kjører i bakgrunnen. 

Overvåkning av tjenester vil innebære å se på om én eller flere prosesser kjører
til en hver tid. NSclient++ har muligheten til å se om en bestemt prosess eller tjeneste kjører eller har stoppet. Her spesifiserers det hva prosessen eller tjenesten heter og sjekken svarer på om denne finnes i prosesstabellen.
\begin{lstlisting}
define service {
        service_description     DHCP Service
        hostgroup_name          dhcp_servers
        check_command           check_nrpe!CheckServiceState!DHCPServer=started ShowAll
        use                     generic_service
}

define service {
  use            generic_service
  hostgroup_name       linux_servers
  service_description     NRPE Check my process
  check_command        check_nrpe!check_process!sshd 1:40
}
\end{lstlisting}
linux-plugin fra nagios-plugins: check\_procs 

Å se at en tjeneste kjører via Windows kan gi falsk informasjon. Et eksempel her er Microsoft's terminal services. Tjenesten står som kjørende i Windows, men brukere får ikke koblet til. Dette kommer av at tjenesten har hengt seg, uten at den står som “stoppet”. Dette merkes ikke før brukere ringer inn og beskriver problemet /cite{http://www.petri.co.il/forums/showthread.php?t=41357}. Som nevnt i x.x vil en bedre sjekk være å teste selve tjenesten, som i neste delkapittel.

\paragraph{LDAP, DNS og DHCP}

Tjenester som LDAP-autentisering, DNS-oppslag og DHCP-leasing er en viktig del av tjenestene IKT-avdelingen leverer.

LDAP-tjenesten gjør at brukere får logget på trådløse nettverk og autentisert seg for andre tjenester IKT-avdelingen leverer. 
http://en.wikipedia.org/wiki/Lightweight\_Directory\_Access\_Protocol

DNS oppslag gjøres hver gang en enhet skal oversette en IP-adresse til et hostname eller omvendt. Uten DNS vil ikke enheten kunne kontakte andre enheter ved å benytte hostname, som brukes i f.eks web-adresser. 
http://en.wikipedia.org/wiki/Domain\_Name\_System

Når en ny enhet kobles til nettverket vil denne få tildelt en IP-adresse av DHCP-serveren. Samtidig får den informasjon om gateway og DNS-servere. Uten dette vil ikke enheten få kommunisert med andre enheter på nettverket. http://en.wikipedia.org/wiki/DHCP

Sjekkene for alle de tre tjenestene vil bli gjort direkte fra Icinga-serveren. Denne står i et eget nettverk. Derfor vil det kunne oppstå situasjoner der Icinga rapporterer at tjenestene fungerer, men det ikke fungerer for brukere tilkoblet andre nettverk. En løsning på dette kan være å kjøre sjekkene via en server i hvert nettverk brukere er tilkoblet.


\paragraph{LDAP}

For å overvåke LDAP-tjenestene benyttes pluginen “check\_ldap” som følger med i pakken nagios-plugins-basic. Pluginen kobler til LDAP-tjenesten og prøver å autentisere en bruker. Her vil sjekken returnere OK, om den fikk autentisert. 

Performancedata har blitt samlet inn for å sette grenseverdier for når Icinga skal gi varsel om treg innlogging. I Figur /ref{ldapauth-inv} ser vi at tjenesten sjekket på fire LDAP-servere, over en måneds periode bruker rundt 0.0044 sekunder på å autentisere. Ut ifra dataen som er samlet settes warning settes til 0.01 sekund, og kritisk settes til 0.02 sekunder.

\paragraph{DNS}

DNS overvåkes av pluginen “check\_dns”. Denne på samme måte som “check\_ldap” kobler til selve tjenesten. Denne fungerer ved å gjøre et DNS-oppslag på en spesifikk IP-adresse, og verifisere dette mot et satt hostname. Dersom dette stemmer vil plugin-en returnere OK, sammen med ytelses-data på hvor lang tid oppslaget tok.

Figur /ref{dns-inv} viser data samlet inn fra to DNS servere over 30 dager. Disse dataene viser forventet tid for et oppslag, og utifra dette ble grenseverdien for WARNING satt til 0.01 sek og CRITICAL til 0.02 sek.

\paragraph{DHCP}

DHCP tjenesten overvåkes med pluginen “check\_dhcp”. Denne sender en DHCPDISCOVER-pakke til DHCP-serveren. Hvis DHCP-tjenesten fungerer får pluginen en DHCPOFFER-pakke som respons. Dersom denne inneholder en korrekt lease, returnerer pluginen OK til Icinga sammen med tiden det tok.

\paragraph{Counters}
Mange interne applikasjoner lar brukes via Terminalservere, her er det viktig å kunne levere et stabilt system til brukerne, 
Sjekk av redundante oppsett
En ordinær plugin henter status for en service som kjører på én host. Ved redundante oppsett vil det ikke nødvendigvis være kritisk om en av nodene er nede. For å vurdere statusen av et cluster kan en kjøre en sjekk på hver enkelt host som kjører den gitte servicen, få tilbake resultat fra hver, og ta en vurdering basert på disse resultatene samlet.

For å overvåke redundante oppsett, har pluginene check\_multi og check\_cluster blitt vurdert.  Forskjellene mellom disse er at check\_cluster i motsetning til check\_multi parser den lokale status.dat filen og ser hvilken tilstand en service eller en host er ved siste sjekk. Pluginen check\_multi derimot kjører aktive sjekker mot spesifiserte hosts, og en kan definere comparison operator som vil bli sjekket mot de returnerte resultatene.

Med check\_multi kan en benytte en eller flere egendefinerte kommandoer som parametere. Disse vil bli parses av check\_multi og kan inneholde alt i fra “echo Hello” til mer avanserte perl script, som kjøres ved hjelp av eval. For å evaluere resultatene kan en definere kriterier som gir et varsel (her brukes standard Icinga states). 

Eksempel:
\begin{lstlisting}
command [ HTTP_Node1 ] = check_http -H 192.168.2.10
command [ HTTP_Node2 ] = check_http -H 192.168.2.11
command [ HTTP_Node3 ] = check_http -H 192.168.2.12
state [ WARNING ] = COUNT(WARNING) > 2
state [ CRITICAL ] = COUNT(CRITICAL) > 3
\end{lstlisting}
For check\_cluster spesiferes det om det er et host- eller service-cluster en skal sjekke. Deretter spesifiseres parametere med navn på host og service, og hvor mange hosts eller services som må være nede før at det skal varsles med warning eller critical. Siden check\_cluster kjører lokalt på Icinga-serveren vil den ikke bruke noe nettverkstrafikk, noe som er positivt. Ulempen er at den ikke gir noen informasjon om hvilken host som er nede eller hvilken host en service feilet på. Det vil si at den gir bare en overordnet status for det redundante oppsettet     

Under vises et eksempel hvor servicen Check HTTP for host-objektene localhost, HiG2, HiG3, og HiG4 blir kjørt og vil gi WARNING om 1 er nede og CRITICAL om 2 er nede: 
\begin{lstlisting}
check_cluster --service -l "Check HTTP"  -d $SERVICESTATEID:localhost:Check HTTP$, $SERVICESTATEID:HiG2:Check HTTP$ ,$SERVICESTATEID:HiG4:Check HTTP$  -w @1 -c @2
\end{lstlisting}

\subsubsection{Databaser}
Tre forskjellige databasemotorer benyttes av IKT-avdelingen. Disse er MySQL, MSSQL og Oracle DB. Disse opererer ikke helt på samme måten. /cite{http://en.wikipedia.org/wiki/Comparison\_of\_relational\_database\_management\_systems}. Derfor blir ikke de samme parameterene overvåket på alle. Felles for alle er:

Connection time (tid det tar å koble til SQL serveren).
Connected users (antall aktive sessioner mot SQL serveren).
Cache hit rate (antall spørringer som blir hentet fra cache i et tidsinterval).

Disse er valgt

Spesifikke
MySQL: Slow queries (antall trege spørringer SQL serveren utfører i et tidsinterval).
MSSQL: Lazy writes
Oracle: Free table space (Plass ledig for tabellene).
Oracle: Switch interval (Overvåker load).


Connection time
Connection time gir beskjed dersom det ikke er mulig å koble til SQL serveren. Hvis denne sjekken gir en timeout, er det fordi sjekken ikke får kontakt på porten til SQL tjenesten. Her definerers det parametere for hvor lang tid det burde ta å koble til. Hvis tilkoblingstiden blir for lang varsler Icinga om dette. Grenseverdier her er valgt ut fra gjennomsnittlig tid det har tatt å koble til i perioden denne har vært operativ. Data for tilkoblingstiden har blitt samplet over 30 dager.

Connected users
Connected users sjekker hvor mange sessioner som er koblet til database tjenesten (per instanse for Oracle DB). Antall aktive sessioner blir samlet inn om hver enkelt database. Derfor defineres thresholds ut fra hvor mange brukere som er koblet til over en periode. Da plukkes uvanlige bruksmøstre opp og kan videre studeres.

Cache hit
Cache hit er hvor ofte data hentes ut fra databasemotorens egen cache, slik at dataen ikke leses fra disk, Dette sparer diskene for I/O operasjoner. Hvis cache hit ligger på et høyt nivå (90-100 \%), indikerer dette at tabellene det spørringes mest mot lagres i cache. Når cache hit ligger under 90 \% kan dette være et resultat av at serveren ikke har nok minne til å lagre tabellene i cache. Dette kan indikere et minneproblem.

Cache hiten er anbefalt fra Oracle sin side å ligge over 90 \% /cite{http://www.dbspecialists.com/files/presentations/buffercache.html}. 
For MSSQL er så nærme 100 \% cache hit et godt utgangspunkt. Dette indikerer at MSSQL klarer å lagre de mest brukte tabellene i minne. /cite{http://www.databasejournal.com/features/mssql/article.php/3932406/Top-10-SQL-Server-Counters-for-Monitoring-SQL-Server-Performance.htm}
MySQL databasene til IKT-avdelingen lagrer all database data i minnet, så her vil det ikke være relevant å sjekke cache hit. Sjekken er satt opp slik at ordinære MySQL-servere vil kunne settes opp med denne sjekken i etterkant.

Basis installering av plugin 
For at Icinga serveren skal kunne snakke med de forskjellige database-motorene trengs en klient for hver av de. 

Oracle
Databaseklienten finnes på Oracle sine nettsider /cite{http://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html}. Den finnes ikke som en deb-pakke, som som brukes for Debian. Det finnes derimot en rpm-pakke, som brukes av blant annet Red Hat. Alien /cite{http://wiki.debian.org/Alien} ble brukt til å konvertere rpm-pakken over til deb-pakke før installasjon på Icinga-serveren. 
\begin{lstlisting}
alien oracle-instantclient11.2-basic-11.2.0.3.0-1.x86_64.rpm 
dpkg -i oracle-instantclient11.2-basic-11.2.0.3.0-1.x86_64.deb
\end{lstlisting}
Videre trengs også en databasedriver, som gjør det mulig for Perl å benytte klienten. For oracle databaser brukes perl DBI driver for Oracle “libdbd-oracle-perl”.

På en Oracle server vil hver database ha sin egen instans /cite{http://searchoracle.techtarget.com/answer/What-s-an-Oracle-instance}. Det vil si at parametre som overvåkes vil være forskjellig fra database til database. Navnene til instansene legges derfor inn som en egendefinert variabel i hver enkel Oracle-servers host-objekt. Når pluginen kjøres sjekkes filen tnsnames.ora /ref{tnsnames} som inneholder tilkoblingsinformasjon for hver enkelt instans.
\begin{lstlisting}
ORA11 =
 (DESCRIPTION = 
   (ADDRESS_LIST =
     (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))
   )
 (CONNECT_DATA =
   (SERVICE_NAME = ORA11)
 )
)
\end{lstlisting}
Check\_multi brukes så for å samle en Oracle servers instanser under samme service. Eksempelvis når cache hit sjekken kjøres, vil check\_multi utføre sjekken for alle instansene. Deretter vil svarene fra instansene samles under samme check cache hit sjekk i Icinga. Dette gjør det mer oversiktlig å overvåke oracle servere.

\begin{lstlisting}
define service {
...
check_command check_multi!check_oracle! -s dbinstances=$_HOSTDBINSTANCES$ -s host=$HOSTADDRESS$ -s mode=sga-data-buffer-hit-ratio -s warning=93: -s critical=90: -s user=$USER5$ -s pass=$USER4$
}

define command {
...
command_line	check_multi -r 32 -f /etc/icinga/objects/commands/check_multi/$ARG1$.cmd $ARG2$
}


eeval [ oracle_health ] =
    	my $chain = "";
    	foreach my $instance (split(/,/,'$dbinstances$')) {
            	$chain .= "-x \"command[ $instance ] = check_oracle_health --connect '$user$'\/'$pass$'\@'$instance' --mode '$mode$' --warning $warning$ --critical $critical$ \" ";
    	}
    	parse_lines("command [ check_oracle ] = check_multi -r 4 $chain");

\end{lstlisting}

MySQL
I MySQL ligger de nødvendige pakkene i Debians pakkebrønnen og kan installeres med apt. De nødvendige pakkene er “mysql-client”, for database koblingen og “libclass-dbi-mysql-perl”, som er en Perl-modul for å kunne koble til en MySQL-server. 
MSSQL
For MSSQL var det vanskelig å finne en databaseklient som er opensource. Her endte vi opp med FreeTDS /cite{http://www.freetds.org/}, sammen med Perl-modulen “libdbd-sybase-perl”

Plugin
Plugin-ene som blir benyttet for databaser er skrevet av firmaet “Consulting \& Solutions” og heter “Check\_MySQL\_Health”, “Check\_Oracle\_Health” og “Check\_MSSQL\_Health” /ref{http://www.consol.com/open-source-monitoring/database-monitoring/}

Disse må kompileres fra kildekoden. For å gjøre dette må en først konfigurere de med riktige parametere. Dette er de samme for alle tre plugin-ene.

\begin{lstlisting}
./configure --prefix=/usr/lib/nagios/plugins/ --with-nagios-user=nagios --with-nagios-group=nagios --with-perl=/usr/bin/perl --with-statefiles-dir=/tmp
\end{lstlisting}

Pluginen kompileres og legges i riktig bane ved å kjøre kommandoene

make
make INSTALL

For å koble til databaseserverne trengs servicebrukere i hver av de. Her holder det med minimale tilganger slik at denne ikke har tilgang til å endre tabeller og spørre etter info. Brukeren vil kun ha tilgang til å kjøre “Server administrasjon” kommandoer.

I MySQL brukes følgende kode for å opprette denne brukeren /cite{http://dev.mysql.com/doc/refman/5.0/en/privileges-provided.html#priv\_usage}:
\begin{lstlisting}[language=SQL]
GRANT USAGE ON *.* TO 'icinga'@'10.60.0.20' IDENTIFIED BY 'Bachel0r'; 
\end{lstlisting}

Script for å opprette brukere i Oracle og MSSQL finnes i vedlegg /ref{sqlscript}.

Konfigurasjonen
Kommandoen konfigureres med muligheten for å bestemme hvilken sjekk som skal kjøre i \$ARG1\$.

Her brukes MySQL som eksempel men dette vil være lik på de andre forskjellige SQL serverne. 
\begin{lstlisting}
command_line $USER1$/check_truedatabase-motor>_health --hostname=$HOSTADDRESS$     
--username=$USER5$ --password=$USER4$ --mode $ARG1$ 
--warning $ARG2$ --critical $ARG3$
\end{lstlisting}
MySQL Cluster

MySQL Cluster er et distribuert oppsett for MySQL. Ved IKT-avdelingen benyttes et MySQL Cluster med NDB som lagringsmotor, der databasene kjører i minnet. Et MySQL Cluster består av tre forskjellige nodetyper:

\begin{itemize}
	\item Management - her konfigureres clusteret og en setter opp hvor mange Data- og SQL-noder som kan kobles til.
	\item Data - oppbevarer dataene i RAM. Disse håndterer lastbalasering, replikering, failover og gjenoppbygging automatisk i mellom hverandre.
	\item SQL - MySQL servere som kobler seg til data-nodene for å hente og lagre data.
\end{itemize}

Den enkleste måten å hente ut statistikk om et MySQL Cluster er å benytte seg av mangement programmet “ndb\_adm” som kan hentes ut fra installasjonspakken til mysql-cluster /cite{http://dev.mysql.com/downloads/cluster}. I ndb\_adm kan en se hvor mange noder av hver type som er tilkoblet og minneforbruket til hver av datanodene. De plugin-ene som benyttes baserer seg på output fra “ndb\_adm”.

Antallet noder tilkoblet overvåkes med pluginen check\_ndbd (https://www.monitoringexchange.org/inventory/Check-Plugins/Database/MySQL/NDB-node-monitoring). Her ble det gjort en endring i koden slik at serveren som ndb\_adm kobler seg til kan spesifiseres som en parameter.

For minnebruk ble det skrevet en egen plugin, da ingen eksisterende plugin ble funnet som tillot å spesifisere hvilke noder som skulle sjekkes. ID-ene til nodene som skal sjekkes ble satt opp som en egendefinert variabel i host-konfigurasjonen. Denne sendes til pluginen via service- og kommando-objektene, som vist under.

\begin{lstlisting}
define host {
       ...
        _NODEIDS 2,3  ;Data-nodes IDs to check memory usage
}

define command {
  …
   command_line   $USER1$/libexec/check_ndb_mem.pl --host $HOSTADDRESS$ --nodes $ARG1$ --warning $ARG2$ --critical $ARG3$
}
\end{lstlisting}
\subsubsection{Microsoft Exchange}

Exchange er en kritisk tjeneste for fylkeskommunen. Her routes og lagres all e-post som sendes ut og inn av alle brukere. 

Gjennom perfmon har en tilgang til en rekke viktige tall /cite{http://www.solarwinds.com/resources/videos/exchange-server-monitoring-best-practices.html} for å måle ytelsen i Exchange. Disse kan overvåkes over NRPE med check\_counter i NSClient++.
\begin{itemize}
	\item Antall tilkoblinger
	\item Gjennomsnittlig responstid
	\item Antall meldinger sendt per sekund. Ved høye tall kan det være mistanke om at mail-serveren blir brukt til spam, eller at det er zombier på nettverket.
	\item Antall LDAP-søk som gir timeout. Feil mot AD.
	\item Økning i SMTP-køen
\end{itemize}

Microsoft har gitt ut egne anbefalinger til grenseverdier. http://gallery.technet.microsoft.com/office/Performance-and-Threshold-d32ff5a6

I tillegg til disse var det ønskelig med en sjekk som testet hele e-post-oppsettet. Til dette benyttes pluginen “check\_email\_delivery” cite http://exchange.nagios.org/directory/Plugins/Email-and-Groupware/check\_email\_delivery/. Her sjekkes det at en e-post kan sendes fra SMTP-serveren. E-posten som sendes ut inneholder en unik ID. Videre kobler pluginen seg til IMAP-tjenesten og sjekker om e-posten med den unike ID-en kom frem. Antall sekunder for hele round-tripen blir målt. Helst skulle en her koblet til en SMTP-server som står utenfor nettverket, men dette var det ikke andledning til.

Det sjekkes også at websiden for Outlook Web Access er tilgjengelig gjennom pluginen “check\_http”. Her burde en nok også sjekket om det var mulig å logge inn.
Overvåkning av Applikasjoner
Muligheten for å se om en applikasjon fungerer slik den skal er en viktig del av overvåkningen. Det er applikasjonene brukerne benytter seg av og vil sende inn feilmeldinger om. En applikasjons tilstand vil bestemmes av flere tjenesters status. I Icinga benyttes et servicegroup-objekt for å gruppere flere service-objekter.

Et praktisk eksempel på dette vises i Figur /ref{servicegroup}. Her vil applikasjonen “Web App for ERP” være avhengig av webserveren for å vise web-grensesnittet til brukerne, en filserver for lesing og lagring av filer, en e-post-server for å sende og motta mail og en databaseserver som inneholder brukerinfo og andre tabeller. 

Konfigurasjonen for dette er vist under. Direktivet “Members” setter medemene i gruppen der hvert service-objekt er “host\_name,service\_description”.

\begin{lstlisting}
define servicegroup {
servicegroup_name ERP_WEBAPP
alias Web App for ERP
members Web1,Check HTTP, File1,Check SMB, Mail1,Check Exchange, DB1,Check MySQL
}
\end{lstlisting}


Her kjøres service-sjekker mot alle tjenestene. Service-objektene grupperes i en servicegroup. 
Dette gjør at vi får et oversiktsbilde over applikasjonen i Icingas web-grensesnitt som vist i Figur /ref servicegroup. Slik blir det enklere for servicedesk å kunne gå inn for å se hva som er feil med “Web app for ERP” om brukere rapporterer om feil på applikasjonen.

Det vil det også være naturlig å sette opp servicedependency-er mellom ERP Web1 og sjekkene for webserveren, filserveren, mailserveren og databaseserveren.

\subsubsection{Infrastruktur}
Infrastruktur består av de grunnleggende enhetene de andre serverne er avhengig av. I dette prosjektet er det definert til: switcher, routere, brannmurer, UPS, virtualiseringsteknologi og serverrommiljø.

Infrastrukturovervåkning er essensielt for å kunne levere IT-Tjenester. Det er viktig at design av overvåkningen fører til at man raskt og effektivt skal kunne oppdage og presentere feil som oppstår. For å få til dette i Icinga benyttes “parent” /ref{parents}. De aller fleste enheter i infrastrukturen (untatt servermiljø) vil være parent for andre enheter. Dette reflekteres i et statuskart i icinga, som vist i Figur /ref{statusmap}.

\paragraph{Switcher}
Switcher er nettverksutstyr som opererer på lag 2 i OSI modellen. IKT-avdelingen benytter switcher med lag 3 funksjonalitet. Lag 3 funksjonalitet vil si at switchen kan kommunisere over IP. Alle switchene IKT-avdelingen benytter støtter SNMP-protokollen, som brukes til overvåkingen.

På switchene overvåkes forskjellige sensorer avhengig av hva de inneholder. Alle switcher har for eksempel ikke vifter.

Det er laget et generisk oppsett som overvåker temperatur, PSU og viftestatus. Hvilken OiD denne informasjonen ligger under varierer fra leverandøren til leverandør. Mange produsenter benytter også samme OiD. 

Dersom en vifte eller PSU raporteres som defekt vil det raporteres som en CRITICAL-status i Icinga. For temperatur er grenseverdiene satt til xx for WARNING og xx for CRITICAL.

Switchene IKT-Avdelingen bruker er forskjellige modeller fra leverandørne Cisco, Dell og HP. Disse overvåkes med plugin-ene "check\_nwc\_health" /cite{http://labs.consol.de/nagios/check\_nwc\_health/} for Cisco og HP og check\_snmp\_powerconnect for Dell /cite{http://exchange.nagios.org/directory/Plugins/Hardware/Network-Gear/Dell/Check-PowerConnect-Switch/details}.

\paragraph{Routere og brannmurer}
IKT-avdelinger benytter Cisco ASA og Cisco PIX routere mellom forskjellige subnettverk. I tillegg utfører de gjerne oppgaver som pakkefiltrering, NAT og IPsec-tunneler.
Ressurser
Som for switcher /ref{switch} brukes "check\_nwc\_health" til å se at sensorer er OK. I tillegg
sjekkes CPU-bruk og minneforbruk gjennom samme plugin. 

For CPU-bruk sjekkes gjennomsnittet over 5 minutter. Grenseverdier er satt til 80 % på WARNING og 90 % på CRITICAL, i henhold til det cisco anbefaler \cite {http://www.cisco.com/en/US/prod/collateral/netmgtsw/ps6504/ps6528/ps12363/white_paper_c11-726161.html}. Høy CPU-bruk kan føre til dårligere ytelse, høy rate av buffer-feil og generelle feil med responsivitet /cite {http://www.cisco.com/en/US/products/hw/routers/ps133/products_tech_note09186a00800a70f2.shtml}

I følge Cisco kan høytminneforbruk under vanlig operasjon indikere at brannmuren er under angrep. /cite{http://www.cisco.com/en/US/products/ps6120/products\_tech\_note09186a0080b8e100.shtml#showmemory}. Dersom en router bruker opp tilgjengelig minne kan det føre til at routeren slutter å svare på kommandoer, telnet-tilkoblinger eller henger /cite http://www.cisco.com/en/US/products/sw/iosswrel/ps1831/products\_tech\_note09186a00800a6f3a.shtml. Cisco anbefaler en grenseverdi på 15 \% ledig minne /cite {http://www.cisco.com/en/US/prod/collateral/netmgtsw/ps6504/ps6528/ps12363/white\_paper\_c11-726161.html}. Grenseverdier for minne er derfor satt til 20 % for WARNING og 15% for CRITICAL.
Failover

Cisco router / Brannmurer har en viktig funksjon som kalles failover. Denne fungerer slik at to like enheter settes opp, der en blir satt som “primary” og den andre som “secondary”, slik at denne kan overta for “primary” om det skulle bli nødvendig. Disse kobles sammen med en seriellkabel. Figur /ref{ciscoasafailover} viser hvordan et Cisco-failover er satt opp. 
\paragraph{Ressurser}

Som for switcher \ref{switch} brukes check\_nwc\_health til å se at sensorer er OK. I tillegg
sjekkes CPU-bruk og minneforbruk gjennom samme plugin. 

For CPU-bruk sjekkes gjennomsnittet over 5 minutter. Grenseverdier er satt til 80 \% på WARNING og 90 \% på CRITICAL, i henhold til det cisco anbefaler \cite {http://www.cisco.com/en/US/prod/collateral/netmgtsw/ps6504/ps6528/ps12363/white\_paper\_c11-726161.html}. Høy CPU-bruk kan føre til dårligere ytelse, høy rate av buffer-feil og generelle feil med responsivitet /cite {http://www.cisco.com/en/US/products/hw/routers/ps133/products\_tech\_note09186a00800a70f2.shtml}


I følge Cisco kan høytminneforbruk under vanlig operasjon indikere at brannmuren er under angrep. \cite{http://www.cisco.com/en/US/products/ps6120/products_tech_note09186a0080b8e100.shtml#showmemory}. Dersom en router bruker opp tilgjengelig minne kan det føre til at routeren slutter å svare på kommandoer, telnet-tilkoblinger eller henger \cite http://www.cisco.com/en/US/products/sw/iosswrel/ps1831/products\_tech\_note09186a00800a6f3a.shtml. Cisco anbefaler en grenseverdi på 15 \% ledig minne /cite {http://www.cisco.com/en/US/prod/collateral/netmgtsw/ps6504/ps6528/ps12363/white\_paper\_c11-726161.html}. Grenseverdier for minne er derfor satt til 20 \% for WARNING og 15 \% for CRITICAL.

\paragraph{Failover}

Cisco router / Brannmurer har en viktig funksjon som kalles failover. Denne fungerer slik at to like enheter settes opp, der en blir satt som “primary” og den andre som “secondary”, slik at denne kan overta for “primary” om det skulle bli nødvendig. Disse kobles sammen med en seriellkabel. Figur /ref{ciscoasafailover} viser hvordan et Cisco-failover er satt opp. 

Dersom primary går ned vil secondary ta over nødvendige ruter, brannmurregler og konfigurasjon. Secondary vil dermed overta IP- og MAC-adressen til primary. Primary vil bli satt som passiv (trenger ikke nødvendigvis å ha en passiv IP adresse, fordi IP kommunikasjon går kun gjennom det aktive interfacet) helt til en manuelt endrer dette tilbake i konfigurasjonen. /cite{http://www.cisco.com/en/US/docs/security/asa/asa80/configuration/guide/failover.html#wp1058096}. 

Sjekkene som settes opp for å verifisere at failover funksjonaliteten fungerer som den skal, og at det ikke har intruffet feil er:
\begin{itemize}
\item Hvis primary er satt som aktivt og secondary er passiv returneres OK.
\item Om primary er satt som passiv returneres WARNING. 
\item Om secondary er satt som aktiv returneres WARNING.
\item Hvis primary eller secondary får en error returneres CRITICAL
\item Hvis failover ikke er konfigurert returneres UNKNOWN. 
\end{itemize}

Til dette benyttes pluginen “check\_cisco\_firewall” \ref{
http://exchange.nagios.org/directory/Plugins/Hardware/Network-Gear/Cisco/Cisco--2D-Check-firewall-ASA-and-PIX/details}

Hvis brannmurene deler management IP på primary og secondary, er det ingen mulighet for å hente ut informasjon fra den passive brannmuren. Da sjekkes failover status bare for primary. I et ideelt miljø burde både passiv og aktiv ha hver sin IP adresse, slik at fysiske feil kan avdekkes på den passive brannmuren.

Begge brannmurene legges i en hostgroup som er lagt på service-objektet for “cisco\_health” slik at lokale ressurser sjekkes på samme måte som switcher. Brannmurene legges også inn i en hostgroup som heter Cisco-failover som benyttes i service-objektet for failover.

\paragraph{VPN}

For brannmurer som har VPN-tjeneste sjekkes antall oppkoblede bruker opp mot det antallet brannmuren er lisensiert for. Begge disse verdiene finnes som SNMP OID-er definert i CISCO-FIREWALL-MIB. Det fantes allerede en plugin som sjekker antall tilkoblede brukere \ref {http://exchange.nagios.org/directory/Plugins/Uncategorized/Software/SNMP/cisco\_asa\_sessions/details}. Denne ble endret til å også hente ut det maksimale antallet og sammeligne brukt kapasitet i prosent mot grenseverdier som kommer inn som argumenter.

\paragraph{Båndbredde}

For å overvåke båndbreddebruk ut av og inn på en port Cisco ASA og PIX finnes to muligheter:

\paragraph{Netflow}

Funksjonen Netflow cite: http://www.cisco.com/en/US/prod/collateral/iosswrel/ps6537/ps6555/ps6601/prod\_white\_paper0900aecd80406232.html fungerer ved at enheten samler inn informasjon om og statistikk over alle pakker som går ut og inn av portene. Dette krevet at Netflow konfigureres på alle routerne og det vil også ta opp ekstra minne og CPU cite: http://www.cisco.com/en/US/technologies/tk543/tk812/technologies\_white\_paper0900aecd802a0eb9.html. Derfor ble det avgjort å ikke benytte Netflow.

\paragraph{Telle pakker}

Både Cisco Pix og ASA har tellere for antall byte som går ut og inn på en nettverksport. For å kalkulere båndbredde bruk over et intervall kan en hente ut disse, vente en gitt periode og hente ut nye verdier. Da vil bruken være ((målepunkt2 - målepunkt1)*8) / antall sekunder.

Mange plugins benytter seg dette ved å lese ut “ifInOctets” og “ifOutOctets” over SNMP. Det er også disse som er benyttet i Ciscos notat “How to Calculate Bandwidth Using SNMP” cite http://www.cisco.com/en/US/tech/tk648/tk362/technologies\_tech\_note09186a008009496e.shtml 

En stor ulempe med å benytte disse er at de er 32 bit, og vil dermed nullstilles kjapt ved høye hastigheter. For 1000Mbps vil tiden det vil ta til telleren går rundt være ((2\^32)-1) / ((10\^9)/8) = ca. 34 sekunder. Se Tabell /ref 

\begin{center}
\begin{tabular}{ | l | p{7cm} |} 
        \textbf{Hastighet} & \textbf{Tid}
	\\ \hline
        10 Mbps & 57 minutter og 15.97 sekunder \\ \hline  
        100 Mbps & 5 minutter og 43.60 sekunder \\ \hline
	1000 Mbps & 34.36 sekunder \\ 
	\hline
\end{tabular}
\label{kalkulering_teller}
\end{table}
\end{center}

Det er derfor anbefalt å bruke 64-bit-variablene ifHCOutOctets og ifHCInOctets i stedet. Cite http://www.cisco.com/en/US/tech/tk648/tk362/technologies\_q\_and\_a\_item09186a00800b69ac.shtml.

Pluginen det er tatt utgangspunkt i for å hente ut båndbreddebruk heter check\_iftraffic64 cite http://exchange.nagios.org/directory/Plugins/Network-Connections,-Stats-and-Bandwidth/check\_iftraffic64/details. Denne er noe omskrevet for å kunne sende inn absolutte verdier som grenseverdier for varsling. I generic-firewall er det satt opp to egendefinerte variabler “WANWARN” og “WANCRIT”, som setter standard grenseverdier for alle brannmurer. For brannmurer der det er normalt med høyere båndbreddebruk er disse variablene overstyrt i konfigurasjonen for host-objektet.

\subsubsection{VMware og Citrix Xen}


Ved IKT-avdelingen er det både et Citrix Xen-miljø og et VMware-miljø. Disse består av servere som kjører hypervisorene ESX 5.1 og Xen 6. Begge er av typen 1 (direkte på hardware) og står for administering av virtuelle maskiner, som er operativsystemer med applikasjoner. Hypervisoren introduserer altså  et nytt lag mellom hardware og applikasjonene brukeren benytter. Host-ene har ansvaret for at de virtuelle maskinene får tilstrekkelig med ressurser for å kunne kjøre applikasjoner installert. 

For overvåkning av virtuelle maskiner brukes NRPE, det overvåkes da som en “egen” server. Overvåkning av servere som kjører hypervisor-ene vil bestå av å sjekke om ressurser strekker til etterspørselen fra de virtuelle maskinene. En eller flere virtuelle maskiner kan kreve mer ressurser enn en server har fysisk. Dette stjeler både CPU-tid, minne og I/O for å håndtere, noe som vil gå utover gjeste-operativsystem og applikasjoners responstid. Videre vil overvåkning av hvor mye ressurser som brukes gi muligheten for å kalkulere når eventuelle skaleringstiltak må innføres. /ref http://pubs.vmware.com/vsphere-51/topic/com.vmware.ICbase/PDF/vsphere-esxi-vcenter-server-51-monitoring-performance-guide.pdf

\paragraph{VMware}

Pluginen “check\_vmware\_api.pl”, som er utviklet av et open source firmaet op5 /ref http://www.op5.com/, er brukt for å hente ut informasjonen fra VMware vCenter. Denne pluginen bruker et SDK-bibliotek i Perl /ref http://www.vmware.com/support/developer/viperltoolkit/ for å utføre API-kall til vCenter. Autentisering skjer ved å sende med brukernavn og passord for en brukerkonto som opprettet i vCenter-serveren med read-rettigheter. For å utveksle informasjon blir SOAP-protokollen benyttet/ref http://en.wikipedia.org/wiki/SOAP via HTTPS. 

http://docwiki.cisco.com/wiki/Troubleshooting\_and\_Performance\_Monitoring\_Virtualized\_Environments

\begin{enumerate}
	\item hvert 5 minutt over en dag 
	\item hvert 30 minutt i en uke
	\item hver 2. time i en måned
	\item en dag over ett år
\end{enumerate}

Pluginen i CLI

./check\_vmware\_api.pl -D <vCenter ip> -u <brukernavn> -p <passord> | -H <host\_navn> -N <vm\_navn> -C <cluster\_navn>  -l <hovedkommando> -s <subkommando> -i <interval> -T <timeshift>

For å overvåke flere parametere kan en legge til kode i pluginen så lenge ønskede parametere er tilgjengelig via API-et. Navnet på funksjoner følger standarden:

<host eller vm eller cluster>\_<hovedkommando>\_info 

Så for eksempel for å legge til en ny CPU-parameter finner en “host\_cpu\_info” funksjonen og legger til en elseif på subkommandoen som brukes for å referere til et gitt parameter i VMware API-et. En kan følge oppsettet på de pluginen som allerede er definert. Dett krever noe kunnskaper om språket Perl.

For alle parametere som blir hentet ut blir tilleggsoppsjonene -i 300 og -T 300 sendt med.
Som nevnt over lagres data i ulike intervall, og opsjonen “-i 300” vil si at det hentes ut data med intervall-ID 300 og vi får da gjennomsnittet for 5 minutter med datapunkt for hvert 20 sekund (standard innhenting i vCenter). Opsjonen “-T” er timsehift i sekunder, som vil si at det returneres data i fra tiden sjekken blir kjørt og 300 sekunder tilbake i tid. 

Etter analyse av output fra pluginen ble det observert at dette var innstillingene som ga oss data om det siste 5 minutters-intervallet. Dette var ønskelig fordi pluginen varsler mot det siste intervallet, så de andre intervallene var overflødige. Andre opsjoner som ble testet var bare “-i 300”, men her kom det 288 resultater tilbake. Dette er antall datapunkt som blir generert i 5 minutters intervallet for en dag. /ref http://pubs.vmware.com/vsphere-51/index.jsp?topic=2Fcom.vmware.wssdk.pg.doc2FPG\_Performance.18.6.html

To counters har blitt tatt ut for overvåkning , og vil være eksempel på hvordan en setter opp sjekker. Disse kan brukes som referanse for utvidelse av overvåkningen av VMware. 

 Parametere som nå overvåkes: : 
/citehttp://docwiki.cisco.com/wiki/Troubleshooting\_and\_Performance\_Monitoring\_Virtualized\_Environments
/citehttp://pubs.vmware.com/vsphere-51/topic/com.vmware.ICbase/PDF/vsphere-esxi-vcenter-server-51-monitoring-performance-guide.pdf

\paragraph{CPU}

 /cite http://www.vmware.com/support/developer/vc-sdk/visdk400pubs/ReferenceGuide/cpu\_counters.html


Counter usage.average (\%) over siste 5 minutt -  warning: 75 critcal: 90 

“Actively used CPU of the host, as a percentage of the total available CPU. Active CPU is approximately equal to the ratio of the used CPU to the available CPU. available CPU = # of physical CPUs x clock rate”

Grenseverdier her er satt til samme nivå som tilsvarende alarm i vCenter, og gir indikasjon på at det kan være en eller flere virtuelle maskiner som krever for mye CPU i forhold til hva hosten har tilgjengelig. Det kan også være et for stort antall virtuelle maskiner på hosten. 

\paragraph{Minne}

Counters 

 usage.average (\%) warning: 80 critical: 90

“Percentage of available machine memory: consumed ÷ machine-memory-size”

Grenseverdier her er satt til samme nivå som vCenter, og vil gi indikasjon på om virtuelle maskiner krever mer minne enn hosten har tilgjengelig. Når det er igjen 6\% minne (free) vil hosten iverksetter enten ballooning og eventuelt swapping. Disse to reallokeringsteknikken krever CPU kraft og er en indikasjon på at minneforbruket er for høyt

\paragraph{Xen}

For overvåkning av Xen-miljøet er det foreløpig en plugin etter det vi fant som gir muligheten til å hente ut informasjon fra hosts og virtuelle maskiner. Pluginen check\_xen\_api.pl, utnytter kall via url mot en RRD-database hvor xapi lagrer data /cite http://wiki.xen.org/wiki/XAPI\_RRDs. 
Antall parametere som er tilgjengelige er ikke like stort som for eksempel VMware. I/O data er foreløpig ikke tilgjengelig, og relevant data er CPU og minnebruk.

RRD-databasen lagrer data i følgende intervall:
\begin{enumerate}
	\item Hvert 5 sekund i en 10 minutters periode
	\item Hvert minutt i en 2 timers periode
	\item Hver time i en ukers periode
	\item Hver dag for ett år
\end{enumerate}

For hvert 5 sekund blir aktuelle datapunkt lagret, og for de tre andre en gjennomsnitts funksjon kjørt og gjennomsnittet fra den aktuelle tidsperioden blir lagret 

Parametere som er valgt for å overvåke Xen hosts:

CPU bruk i prosent - warning: 80 critical: 90 

Total bruk for alle kjerner / antall kjerner

Minne bruk (MB og \%, varsler på \%) - warning: 80 critical: 90

Totalt allokert minne - ledig minne 

Et problem ble støtt på under implementeringen av check\_xenplugin.api som fikk stor innvirkning på returnert resultat fra RRD-databasen. Etter å ha lest gjennom koden til selve pluginen og “biblioteket” XenAPI som også er skrevet av op5, ble det oppdaget at denne pluginen bruker siste datapunkt fra intervall nr.1 nevnt over. Resultatet vil da bare være ett datapunkt. Dette er vanskelig å sette varsel på, da en spike kan skje når gitt sjekk kjører. Her ble det avgjort å legge til en ny opsjon for å angi over hvor lang tidsperiode en skal hente ut data. Returnert resultat fra gitt tidsperiode blir gått gjennom og en gjennomsnittsverdi av dette returnert. Dette er foreløpig bare implementert for CPU- og minnebruk for en host.

\paragraph{Xen}


\subsubsection{Trådløse kontrollere}

De trådløse kontrollerne som benyttes av IKT-avdelingen mangler støtter for SNMP-get for informasjon som hentes ut fra switcher og brannmurer som  CPU- og minnebruk. Dette vil i følge produsenten komme i en senere firmware-oppdatering.
Noe av dette kan løses ved å bruke SNMP-traps i stedet og definere verdier for når disse skal sendes ut direkte på kontrollerne. Her ble traps som omhandler kontrollerne og var relevante for IKT-avdelingen satt opp:

\begin{itemize}
	\item Hardware feil med kontrolleren
	\item Ressursmangel på kontrolleren
	\item Rogue AP - et udefinert aksesspunkt er oppdaget av de andre aksesspunktene.
	\item Failover til annen kontroller
	\item Feil med kontakt mot Radius
	\item Lisens utløpt
\end{itemize}

For å få til dette trengs et mellomledd som kan motta SNMP-traps på Icinga-serveren, tolke trap-meldingene og sende informasjonen videre til Icinga. 

For å lytte etter SNMP-traps benyttes SNMPtrapd (http://www.net-snmp.org/docs/man/snmptrapd.html). Her mottas alle traps som sendes med riktig community. Disse sendes så videre til snmptt (SNMP Trap Translator - http://snmptt.sourceforge.net/). Her har defineres de traps-ene en er ute etter, informasjon om OID-ene og kommandoen som skal kjøres når denne mottas.

SNMPtt trenger konfigurasjon for alle OID-ene som skal prosesseres. Disse kan opprettes med snmpttconvertmib ut i fra en MIB-fil slik:

\begin{lstlisting}
root@icinga1:/usr/share/mibs/netsnmp# snmpttconvertmib --in=MERU-WLAN-MIB.my --out=meru.conf --exec='/usr/lib/nagios/plugins/libexec/submit_check_result "$aA meru_$N 2 $D"
\end{lstlisting}

Eksempel på en OID som blir generert i filen meru.conf:

\begin{lstlisting}
EVENT mwlRogueApDetected .1.3.6.1.4.1.15983.3.1.3.13 "Status Events" Normal
FORMAT $*
EXEC /usr/lib/nagios/plugins/libexec/submit_check_result $aA meru_$N 2 "$D"
SDESC
A rogue AP is detected. The AP id, mac address, and other information are described in mwlTraContent.
EDESC
\end{lstlisting}

Her benyttes variabler i snmptt (cite http://snmptt.sourceforge.net/docs/snmptt.shtml#Variable-substitutions):
\begin{itemize}
	\item IP-adressen til snmp agenten, altså kontrollereren
	\item Navnet på trap-en
	\item Beskrivelse på trap fra konfigurasjonfila.
\end{itemize}

SNMPtt vil så kjøre kommandoen definerte under “EXEC” for OID-en, som for dette tilfellet er å sende informasjonen videre til scriptet “submit\_check\_result”. Dette tar fire argumenter:

\begin{itemize}
	\item IP-adresse eller hostname 
	\item Service description
	\item Returkode som setter status på tjenesten (0-3)
	\item Plugin-output
\end{itemize}

Service description for alle meru traps som sendes inn vil da være “meru\_” + navnet på trap-en. Som plugin-output er det lagt inn beskrivelse av trap-en, da denne som regel er noe mindre kryptisk en navnet.

Scriptet vil så skrive dette sammen med et timestamp til icinga.cmd som Icinga sjekker periodisk etter resultat av passive sjekker.

En ting å merke seg her er at en ikke vil få informasjon når tjenesten er OK igjen, og må sette tjenestene til OK manuelt i Icingas webgrensesnitt.

\subsubsection{Serverrommiljø}

For å overvåke temperatur og luftfuktighet på serverrommet ble det kjøpt inn en APC NetBotz 200 \ref{https://www.apc.com/products/family/index.cfm?id=346} med fire eksterne sensorer. Disse ble plassert slik at det er to sensorer på hver side av rack-raden. En vil dermed kunne se temperaturforskjellen mellom forsiden av serverne, ved luftinntak og baksiden, der varmluft går ut.

Hver sensor måler både temperatur og luftfuktighet. For luftfuktighet støttes bare relativ luftfuktighet.

\paragraph{Luftfuktighet}

Relativ luftfuktighet er definert som “forholdet mellom partielltrykket til vanndamp, i en gassblanding av luft og vann, og vanndampens metningstrykk ved en viss temperatur. som gir oss prosentandelen av vann i luften. (cite http://no.wikipedia.org/wiki/Luftfuktighet). 

Det er også mange enheter som overvåker duggpunkt, som vil si temperaturen en viss mengde luft må avkjøles til for at vanndamp skal kondensere. Ved en økning i relativ luftfuktighet vil duggpunktet nærme seg luftemperaturen. Ved 100\% relativ luftfuktighet vil temperaturen og duggpunktet være like. 

I “Sun Microsystems Data Center Site Planning Guide” anbefales en luftfuktighet på 45 \% - 50 \%. Det meste av datautstyr kan operere innenfor et bredere intervall enn det, typisk 20 \% - 80 \%. Men de anbefalte verdiene er satt for at det skal være et buffer dersom en har klimaanlegg som kontrollerer luftfuktighet, og det slutter å fungere. /cite http://docs.oracle.com/cd/E19065-01/servers.e25k/805-5863-13/ch3.html\#98939 Andre, som “American Society of Heating, Refrigerating and Air-Conditioning Engineers” (ASHRAE) anbefaler at den relative luftfuktigheten ikke bør overstige 60 \%, mens den nedre gresen er basert på duggpunkt og satt til 5.5°C, der den relative luftfuktigheten vil variere mellom 25 \% og 45 \% /cite http://tc99.ashraetcs.org/documents/ASHRAE\_Extended\_Environmental\_Envelope\_Final\_Aug\_1\_2008.pdf. Disse verdiene er også anbefalt av Cisco cite http://www.cisco.com/en/US/solutions/collateral/ns340/ns517/ns224/ns944/white\_paper\_c11-680202.pdf, og omtalt som vidt akseptert. 

For høy luftfuktighet kan føre til kondens, som igjen kan føre til korrosjon på komponenter. Ved lavere luftfuktighet øker faren for utladninger av statisk elektrisitet (kritisk ved 30 \%), som kan føre til utladninger med ekstremt høye spenningsverdier, som kan ødelegge komponenter.

\paragraph{Temperatur}

Det er mye uenighet rundt anbefalte verdier for temperatur i serverrom. I et studie utført ved University of Toronto /cite http://dl.acm.org/citation.cfm?id=2254778, ble det samlet inn data fra tre forskjellige organisasjoners datasentre, deriblant Googles. I studiet ble det konkludert med at faren for hardware-feil ved høyere temperatur øker mindre enn det som har vært vanlig å basere seg på. For DRAM-feil og “node outages” fant de ingen korrelasjon til temperaturøkning for intervallet i testen (15°C - 60°C). I dette studiet ble det ikke målt eller tatt hensyn til luftfuktighet. 

ASHRAE anbefaler en inntakstemperatur 18°C - 27°C, mens Sun anbefaling er 20°C - 23°C. Sun bregrunner sin anbefaling med at det er lettere å opprettholde trygge verdier for relativ luftfuktighet. ASHRAE viser også til studier som viser at det totale strømforbruket kan gå opp ved høyere temperaturer fordi enheter øker frekvensen på egne vifter. http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=4544393&url=http\%3A\%2F\%2Fieeexplore.ieee.org\%2Fxpls\%2Fabs\_all.jsp\%3Farnumber\%3D4544393

\paragraph{Plugin for overvåkning av temperatur og luftfuktighet i Icinga}

Det fantes allerede en plugin for å sjekke sensorverdiene på APC NetBotz (http://exchange.nagios.org/directory/Plugins/Hardware/UPS/APC/check\_netbotz/details). Men denne sammenlignet verdiene med grenseverdier satt i konfigurasjonen på enheten. Det var ønskelig å samle mest mulig av konfigurasjon på Icinga-serveren, derfor ble pluginen omskrevet til å kunne ta inn øvre og nedre grenseverdier som argumenter.

\paragraph{UPS (Uninterruptible Power Supply)}

UPS, på norsk ofte kalt avbruddsfri strømforsyning blir benyttet til å opprettholde strøm til alle enheter på IKT-avdelingens serverrom, dersom strømnettet skulle falle ut og filtrere den strømen slik at utstyr ikke vil bli skadet om spenningen skulle spike.

Ved IKT-avdelingen benyttes UPS-er av fabrikatene APC og HP.

For APC overvåkes:
\begin{itemize}
 	\item Battery capacity - igjen av charge
	\item load
	\item voltage in/out
	\item internal temp
\end{itemize}

For HP overvåkes:
\begin{itemize}
	\item voltage in/out
	\item Battery current
	\item battery capacity
\end{itemize}

For både HP og APC overvåkes alle parametere direkte over SNMP med pluginen “check\_snmp” fra nagios-plugins. Her er OID-ene definert direkte i service-objektene.

\subsubsection{Varsling}

Varsling er en funksjon i overvåkningsløsningen som krever en del finjusteringer og balansering av parametere over tid. Det vil være en balansegang med å varsle for mye og filtrere for grovkornet. Et tegn på et godt overvåknsingssystem er at det er fokusert, og ikke gir oveflødig mengde informasjon /cite {Building a Monitoring Infrastructure with Nagios}. Dersom det ofte sendes ut “falske varsler” kan dette føre til at en alvorlig hendelse ikke blir oppdaget selv om det faktisk sendes ut varsel. Når varsler sendes ut er det til de som vil og trenger å få de.

\paragraph{Avhengigheter}

For å holde antallet varsler som sendes ut nede benyttes avhengigheter som beskrevet i /ref {servicedependency} og /ref {parent} for å ikke få mer enn en melding ved følgefeil. “Parent” har blitt benyttet til å reflektere det fysiske nettverksoppsettet. Service dependency-objekter er satt opp for noen tjenester. For eksempel tjenester som blir sjekket via NRPE vil være avhengig av at NRPE-daemonen på gitt host kan motta henvendelser.


\paragraph{Konfigurasjon}

I Icinga kan man lage kontakter og legge disse i kontaktgrupper. Oppsettet følger samme logikk som at et hostgroup-objekt referer til en eller flere host-objekt i et service-objekt.
Det vil si at contact- og contactgroup-objekter refereres til i et service- eller host-objekt. Disse kontaktene kan bli varslet om service-objektet får en annen status enn OK. Dette konfigureres i service-objektet sammen ved hvilke tilstander som skal varsles. Disse tilstandene er vist i tabell \ref{notications}.

Når en feil oppstår vil Icinga vurdere ulike konfigurasjonsopsjoner før det eventuelt sendes ut et varsel. Om konfigurasjonsopsjonene tilsier at det skal varsles, vil Icinga gå igjennom filtre som er ferdig definert, som for eksempel om kontakten eller gruppen skal ha varsel via sms eller email. 

% TABELL KONFIG

\paragraph{Flapping}

I Icinga defineres “flapping” som når et host- eller service-objekt skifter state for ofte, noe som resulterer i mange problem- og recoveryvarsler. cite{http://docs.icinga.org/1.8/en/flapping.html} Dersom detektering av flapping er konfigurert for objektet vil Icinga stoppe varsler for det dersom prosentandelen flapping overstiger en konfigurert grense. Objektet regnes som å ha startet å flappe når andelen for første gang overstiger en “høy”-grense og som å stoppe å flappe når andelen igjen er under en “lav”-grense.

Denne prosentandelen er kalkulert ved at
\begin{itemize}
	\item Lagrer resultatet for de siste 21 sjekkene.
	\item Finner når state-endring skjer 
	\item Kalkulerer flap prosent ut fra andelen state-endringer
	\item Vekter nyeste sjekker mer
\end{itemize}

Som standard er denne grensen satt til 20.0 for høy og 5 for lav i Icinga.cfg. Men den kan også konfigureres på hvert host- og service-objekt med direktivene “low\_flap\_threshold” og “high\_flap\_threshold”, som vist i eksempelet under:

\begin{lstlisting}
define host {
	name important_servers  		#template
	use generic_host
	flap_detection_enabled          1     ; Flap detection is enabled
	low_flap_threshold		70    ; Stop flapping at 70 %
	high_flap_threshold		80    ; Start flapping at 80 %
	register			0
}
\end{lstlisting}

\subsubsection{Oppsett av kontakter og kontaktgrupper}


IKT-avdelingen ønsket å kunne styre kontaktinformasjon og kontaktgrupper fra Active Directory. Det ble bestemt at ansvarsforhold skulle gjenspeiles i kontaktgrupper /ref {vedlegg møte}, for eksempel “ts\_ansvarlig” eller “printer\_ansvarlig”. Icinga støtter ikke integrasjon mot LDAP i konfigurasjonsfilene, men siden disse er rene tekstfiler kan de enkelt opprettes og endres med script. Vi var i utgangspunktet skeptiske til å la et script gjøre endringer i konfigurasjonsfiler, da vi var redd for at dette kunne medføre en konfigurasjon med feil, som igjen ville føre til at Icinga ikke ville kunne lese ny konfigurasjon. 

Icinga har en funksjon som gjør at en kan teste konfigurasjonen etter feil med en opsjon på binærfilen (--verify-config). Icinga vil da ta utgangspunkt i rot-konfigurasjonsfilen (icinga.cfg) for å sjekke alle konfigurasjonsfilene. Dette gjør at alle konfigurasjonsfilene må sjekkes og ikke bare de som lages for kontakter. Dermed vil ikke kontakter og kontaktgrupper bli oppdatert dersom det allerede er en feil i konfigurasjonen. 

Det ble skrivet et perl-script (ref vedlegg X) som henter ut kontakter og kontaktgrupper fra en bestemt OU i Active Directory. Scriptet kalles fra et bash-script (ref vedlegg X) som henter resultatet fra synkroniseringen og sender dette til Icinga. En cron-jobb er satt opp for å kjøre synkroniseringen én gang i timen.

Måten scriptet fungere på:
\begin{enumerate}
	\item Henter alle medlemmer av gruppe “icinga\_kontakter” og medlemmer av grupper som er medlem.
	\item Oppretter en konfigurasjonsfil for hver av medlemmene.
	\item Henter alle grupper under “Kontaktgrupper”.
	\item Henter alle grupper under “Kontaktgrupper”.
	\item Det opprettes en egen service-template der kontaktgruppen er satt til å få meldinger, slik at tjenester kan arve fra denne.
\end{enumerate}

%Trestruktur i AD:


For hver gang en konfigurasjonsfil skrives blir det først tatt en backup dersom en fil med gruppe- eller kontaktnavnet finnes fra før. Etter at den nye filen er skrevet, sjekkes konfigurasjonen og dersom det oppdages feil vil backupen bli kopiert tilbake. 

Til slutt sendes resultatet som en passiv sjekk til Icinga. Dersom ingen feil oppstår sendes OK. Hvis ikke vil det gis en CRITICAL der feilmeldingene blir sendt med som resultat av sjekken. Det sjekkes også om e-post-adresse og mobilnummer er definert for alle kontakter. Hvis dette ikke  er satt vil det gis en WARNING på service-objektet “Contact sync” i Icinga.

For å sikre at synkroniseringen kjører er service-objektet satt opp med en freshness-sjekk. Dette vil si at det forventes at Icinga mottar et resultat av sjekken hver time (pluss en feilmargin på 1 minutt). Dersom det ikke skjer vil det bli satt en feil på “Contact sync”. Konfigurasjonen for service-objektet er vist under:
\begin{lstlisting}

define service contact_sync {
   use 				generic_service
   host_name      		localhost
   service_description  	Contact sync
# Only use passive checks for this service
   active_checks_enabled   	0
   passive_checks_enabled  	1
   check_freshness      	1
   freshness_threshold     	3660 ; 1h + 1 min splay time
# if we don't get a passive result within freshness_threshold this will be run
   check_command     		check_dummy!2 "No contact sync has been run for 24hrs" 
}
\end{lstlisting}

\paragraph{Timeperiod}

Objektettypen timeperiod er sterkt knyttet til kontakter. Her kan en definere perioder for varsling. En har mulighet til å definere spesifikke dager, datoer eller hver n-te dag. 

Det var ønskelig at det ikke skulle sendes ut varsler når IKT-avdelingen har servicevindu, den første onsdagen etter andre tirsdagen i hver måned (dagen etter Patch-Tuesday fotnote http://en.wikipedia.org/wiki/Patch\_tuesday). For å få til dette ble det først prøvd å definere det slik:

\begin{lstlisting}
define timeperiod {
	tuesday 2 +1       15:00-04:00
}
\end{lstlisting}

Dette fungerte imidlertid ikke. Løsningen ble å definere perioden for tirsdagen og onsdagen, for så å ekskludere tirsdagen. Slik:
\begin{lstlisting}
define timeperiod {
        timeperiod_name 	patch_tuesday
        alias           	Patch tuesday
        tuesday 2          	00:00-24:00  ;second tuesday of every month
}
\end{lstlisting}

\begin{lstlisting}
define timeperiod {
        timeperiod_name         service_vindu
	 alias			Servicevindu
        tuesday 2 - wednesday   15:00-04:00
        exclude patch_tuesday
}
\end{lstlisting}

\paragraph{Eskalering}

Når varsel har blitt sendt ut, og state-en til et host- eller service-objekt ikke har endret seg over en definert tidsperiode, kan et eskalerings varsel sendes. Contact- eller contactgroup-objektene som er referert til i et host- eller serviceescalation-objekt, vil da motta SMS eller e-mail om hendelsen .

Et eksempel på når dette kan være nyttig er om ledere for et driftsteam ønsker å bli varslet dersom temperaturen på serverrommet fortsatt ligger over varselsgrensen etter at 10 varsler er sendt ut til ansvarlige for kjølingen. Her får lederen mulighet til å ta nødvendige avgjørelser for at problemet skal løses. Dette er vist under:
\begin{lstlisting}
define serviceescalation {
	hostgroup_name		temperature_sensors
	service_description	Check Temperature
	contact_groups		team_leaders
	first_notification	10	# Ten notifications has to be sent before escalation
	last_notification	15	# After fiftheen notifications, this escalation stops. “0” is forever.
	notification_interval	60 	# Escalation notifications are sent every 60 minutes (default 45)
	escalation_options	c	# Only use escalation when service  is C(ritical)
	escalation_period	op_hours  # Only escalate during hours of operations
}
\end{lstlisting}
Det samme kan benyttes på host-objekter ved at ikke service\_description defineres:
\begin{lstlisting}
define hostescalation {
	hostgroup_name		domain_controllers
	contact_groups		big_bosses
	first_notification	3 	last_notification	5 # When does escalation notifications stop
	notification_interval	50
	escalation_options	d #Only use escalation when host is D(own)
}
\end{lstlisting}

\paragraph{Varslingsmelding}

Selve varslingsmeldingene sendes ut først når host- eller service-objekter er i en hardstate (/ref beskrevet i x.x). Et eksempel er om en brannmurs hostsjekk returnerer DOWN. Da er det ikke ønskelig å varsle over SMS eller e-post, dersom det er snakk om et par ping som mistes. For eksempel kan en sjekk som har returnert DOWN kjøres to ganger til, med et intervall på ett minutt, før en hardstate settes, slik:

\begin{lstlisting}
define host {
   use 	generic_host     # Inherit basic config. check_ping for host_check
   host_name	hig-fw1
   max_check_attempts           2 # Number of checks before hardstate
    retry_check_interval        1 # 60 seconds between each consecutive check
}
\end{lstlisting}

For et contact-objekt kan det settes opp ett eller flere command-objekt for både hosts og servicer som skal brukes for utsending og formatering av varslingsmeldingen.  

I eksempelet under brukes command-objektet notify-host-by-email og notify-host-by-sms for varslingsmeldinger:
\begin{lstlisting}
define contact {
   contact_name Kari Sysadmin
   email kari@company.org
   pager 480 88 256 
   host_notification_commands    host_problem_email, host_problem_sms
   service_notification_commands service_problem_email, service_probleml_sms
}
\end{lstlisting}

I eksempelet under vises et command-objekt fra selve implementasjonen. Her benyttes sendmail ref/{http://en.wikipedia.org/wiki/Sendmail} til å sende en epost til en SMS-gateway.

\begin{lstlisting}
define command {
   command_name host_problem_sms
   command_line /usr/bin/printf "%b" "Subject:$CONTACTPAGER$\n***** Icinga *****\n\nHost: $HOSTNAME$\nAddress: $HOSTADDRESS$\nState: $HOSTSTATE$\nTime: $SHORTDATETIME$\nInfo: $HOSTOUTPUT$" | /usr/sbin/sendmail -f icinga@hedmark.org -v $CONTACTPAGER$@smsgw.sms
}
\end{lstlisting}

Varslingsmelder som sendes over SMS vil være korte og lettfattede, mens de som sendes til e-post gjerne er lengre og inkluderer mer utfyllende informasjon. Informasjonen som sendes ut hentes ut ved hjelp av makroer i Icinga /ref{http://docs.icinga.org/latest/en/macrolist.html}. 

Alle varslingsmeldinger sendes fra en og samme e-post-server. Dette er ikke helt ideelt fordi en vil miste både SMS- og e-postvarsling, dersom e-post-serveren skulle slutte å fungere. Løsningen vil være å definere en fallback-server som ble brukt hvis Icinga ikke får kontakt med e-post-serveren. 

\paragraph{Kritisk Varsling}

For kritiske tjenester og utstyr er det i konfigurasjonen defineret et eget generisk objekt som brukes av de service- og host-objektene som anses som kritiske. Dette gjelder domenekontrollere, nettverksutstyr på hoveddatarommet, temperatursensorer og UPS-er. Disse objektene vil sjekkes oftere enn det som er satt som standard. Varslingsmelding vil også sendes til alle ved IKT-avdelingen om en hendelse skulle inntreffe, også utenom arbeidstid og i servicevinduet.

\subsubsection{Statusvisning}

Icinga har allerede som nevnt i x.x et webgrensesnitt. Dette er et verktøy for å utføre handlinger på hosts og servicer. Her finnes også et “tactical overview”, som vist i figure /ref. Det er ikke tilrettelagt for å få vist en kort, og beskrivende beskjed om hva som er galt på de host-ene og tjenestene med feil på en stor skjerm. Det vises et antall for de ulike statusene, men her krever det flere handlinger for å få en bedre oversikt, og er tilrettelagt for administrering. Det ble derfor besluttet å utvikle et webgrensesnitt som er tilpasset IKT-avdelings behov.

%Bilde: Icinga Classic

De som sitter på servicedesk og besvarer henvendelser vil være hovedbrukerene av statusvisningen. Den skal være et hjelpemiddel for å få et overblikk over tjenester og serveres tilstand.

\paragraph{Design}

For at statusvinduet skulle imøtekomme IKT-avdelingens ønsker, ble det besluttet å gjøre utviklingen i iterasjoner. Ofte vet ikke brukeren hva de vil ha før de ser et utkast og prosessen har begynt. For utviklingen av statusvinduet har designprosessen beskrevet i ISO 9241-210 blitt fulgt. Der er det beskrevet fire aktiviteter som går i syklus til en får et tilfredsstillende resultat:

\begin{itemize}
	\item Understand and specify the context of use
	\item Specify the user and organizational requirements
	\item Produce design solutions
	\item Evaluate designs against requirements.
\end{itemize}

Utviklingsprosessen ble startet med et møte med hele IKT-avdelingen for å presentere gruppens forslag til utkast på designet, som vist i  /ref mockup. Her kom det frem forslag om å vise temperaturene fra serverrom-sensorene som en terning der det fysiske oppsettet kom frem.

Eksisterende programvare for denne type fremvisning ble funnet etter litt søk, og det ble besluttet å gjenbruke Nagdash cite https://github.com/lozzd/Nagdash. Løsningen var et godt utgangspunkt for det visuelle, og er skrevet i språket PHP, noe gruppemedlemmene føler seg komfortable med og IKT-avdelingen har benyttet seg av i tidligere prosjekter. 

Nagdash baserer uthenting av informasjon om host- og serviceobjekter på nagios-api cite https://github.com/xb95/nagios-api, som er en tjeneste som må installeres på Icinga-serveren og setter opp et API over HTTP. Icinga har sitt eget API som det var ønskelig å benytte. Uthenting av informasjon måtte derfor endres til å bruke kall til API-et som Icinga-web tilbyr /cite https://wiki.icinga.org/display/Dev/Icinga-Web+REST+API.

Gjennom to iterasjoner kom det frem flere ønsker som ble lagt inn:
\begin{itemize}
	 \item Uthenting av driftsmeldinger via RSS fra portal.hedmark.org
	 \item Endre utseende for “Known Services”
	 \item Sette kolonnene med hosts og servicer ved siden av hverandre 
	 \item Hente ut og grafe antall åpne, lukkede, og mottate saker fra sakssystemet Footprints
	 \item Fjerne irrelevant informasjon som hvilket attempt en gitt service-sjekk er på
\end{itemize}

Det ble også rapportert en bug om at datoen på skjermen ikke endret seg før etter en sideoppfrisking. Koden som oppdaterer datoen var ikke lagt inn i funksjonen som sørger for automatisk oppdatering. Dette viser viktigheten av å ha brukertesting, da en slik bug kan være vanskelig å oppdage.

Etter at all funksjonalitet og design var på plass ble all kode gjennomgått av gruppen i fellesskap for å kvalitetssikre løsningen og sørge for at all ikke-triviell kode var kommentert.

%Bilde Mockup

Nagdash med oversatte API-kall:

%Bilde Nagdash med oversatte API-kall:

Etter første iterasjon:
\begin{itemize}
	\item Temperatur fra serverrommet har blitt lagt til
	\item Antall mottate og lukkede saker fra Footprints er lagt til
\end{itemize}

%Bilde Etter første iterasjon

Sluttresultat:
\begin{itemize}
	\item Visualisering av retning på luftstrøm
	\item Temperatur fra de sensorene som er konfigurert
	\item Luftfuktighet
	\item Kolonnene for host og services er satt ved siden av hverandre
	\item Driftsmeldinger fra portal.hedmark.org
	\item Grafing av lukkede saker som er mottat i dag, lukkede saker fra alle mottate saker,
	mottate saker i dag og totalt antall åpne saker.
\end{itemize}

%Bilde Sluttresultat

\paragraph{Arkitektur}

Statusvindu definerer strukturen for HTML og inkluderer CSS- og Javascript.

Hver av modulene “footprints.php, netbotz.php og rss.php” retunerer et javascript-objekt med data ut fra ajax-kall fra external.js. Dataene bearbeides og settes inn i riktig “div” i html-en med javascript. Nagdash returnerer rå HTML, da denne inneholder tabeller og annen markup i tillegg til dataene.

I filen external.js hentes data fra de ulike modulene og settes inn i statusvindu dynamisk gjennom Ajax i et bestemt intervall.

%Bilde Arkitektur

\paragraph{Nagdash}

For å hente ut data fra Icinga benyttes REST-api-et til Icinga-web. Her kan en sette opp en spørring som kan se slik ut:

service/filter[(blalba)]/columns[(jadda jadda)]/api\_key=test\_api\_key/json

Da får en et javascript objekt ut med de kolonnene en har bedt om.

Vi har totalt 6 spørringer og de ulike gjør følgende:
\begin{enumerate}
	\item  hostQuery henter ut alle hosts som har status DOWN eller UNREACHABLE
	\item  serviceQuery henter ut alle servicer som har en UP host, men en service som er enten WARNING eller CRITICAL
	\item  hostTotalQuery henter ut alle hosts, med en kolonne som forteller hvilken state den er i. Dette blir brukt for å regne ut et antall innen for hver state.
	\item  serviceTotalQuery samme som 3., men henter alle servicer.
	\item  hostPriorityQuery henter ut en og en host basert på objekt id. Informasjonen brukes videre for å sjekke om den har en prioritets variabel satt, som vil føre til at den blir prioritert ved fremvisning.
	\item  servicePriorityQuery samme som 4., men henter her ut for en service
\end{enumerate}

\paragraph{Footprints}

For uthenting av antallet saker innenfor ulike kategorier i Footprints ble det benyttet SQL-spørringer direkte mot databasen. IKT-avdelingen ønsket å få en graf om følgende antall om saker:
\begin{itemize}
	\item Mottat i dag
	\item Både lukket og mottat i dag
	\item Lukket av alle mottate saker
	\item Antall aktive saker
\end{itemize}

I footprints.php vil returnert data fra alle de 4 spørringene bli slått sammen til et array som videre returneres som et JSON-objekt til external.js via AJAX. 

For å grafe returnert resultat i external.js ble jQuery biblioteket Highcarts benyttet. Det ble først testet et annet bibliotek for grafing: jqBarGraph, men dette hadde manglende konfigurasjonsmuligheter.  

I utdraget nedenfor vises koden for å definere hver søyle i diagrammet (“categories”), og sette de ulike dataverdiene med stats.<variabel>:
\begin{lstlisting}
xAxis: {
   categories: ['Closed(today)', 'Received(today)', 'Closed(overall)', 'Active(overall)']

series: [{
         name: 'Amount',
         data: [{ y: stats.Closed,
                  color: '#32CD32'},
                { y: stats.Received,
             color: '#FF0000'},
                { y: stats.ClosedAll,
             color: '#32CD32'},
                { y: stats.Open,
             color: '#FF8F00'}
               ]
         }]
\end{lstlisting}

Visning søylene uten tall ga bare visualisering av forholdet mellom de ulike kategoriene, så det ble lag til konfigurasjon for å vise selve antallet over hver søyle, slik: 

\begin{lstlisting}
dataLabels: {
               enabled: true,
               style: {
                  fontSize: "16px",
                  lineHeight: "auto"
               }
\end{lstlisting}

Standard font-størrelse var for liten, så denne ble justert opp. I Internet Explorer 9.0 ble da tallet flyttet for høyt over søylen i forhold til standard høyde. En løsning på dette ble funnet via siden for rapportering av feil til Highcharts /cite https://github.com/highslide-software/highcharts.com/issues/1567

Endring:

\begin{lstlisting}
lineHeight: "auto"
\end{lstlisting}

Figur(IE Bug) og Figur (IE Endring)  viser høydeforskjellen, høyre er før endring og venstre etter:

\paragraph{Netbotz}

Det var ønskelig at det skulle være enkelt å legge til nye sensorer for temperatur og luftfuktighet. Alle sensorene oppdages automatisk av pluginen som utførerer sjekkene for Icinga. Via API-et til Icinga-web hentes siste verdi for denne sjekken ut. Samtidig får en ut hvilken ID hver av sensorene har fått. I Javascript mappes hver sensor til riktig rad.

Utdrag fra external.js
\begin{lstlisting}
 var front_layout = [2, 1]; // The netbotz sensor IDs for the front row
  var back_layout = [5, 4];  // and the back
  var columns = Math.max(front_layout.length, back_layout.length); // Largest row is used 
...
  var room = new Image(); // Set up background image for the div
  room.onload = function() {
      $('#serverroom_climate').css('width', this.width);
      $('#serverroom_climate').css('height', this.height);
      $('#serverroom_climate').css('background-image', 'url(' + this.src + ')');
   };

   // Set the background image to be one with the right number of columns
   room.src = "image.php?sensor_cols=" + columns;
\end{lstlisting}

Grafikken for servermiljø tilpasses automatisk etter den raden med flest antall sensorer, ved å lime sammen riktig antall bilder dynamisk gjennom GD i PHP. (se image.php i vedlegg x.x).

\paragraph{RSS}

RSS-feeden hentes inn fra IKT-avdelingens egen driftsfeed, der meldinger til alle brukere legges ut. Dersom det ikke er noen meldinger vil det ikke vises noe. Hvis lengden på feeden overstiger det som får plass på én linje vil den begynne å scrolle bortover. Dette gjøres med jQuery-pluginen /ref http://plugins.jquery.com/marquee/.

\paragraph{Prioritering}

Standard visning av et varsel er å vise den som kom inn sist øverst. Ved tilfeller der det er flere varsler, var det ønskelig å kunne gi en prioritering for å få de viktigste varslene til å komme øverst i listen. For å prioritere host-objekter som er DOWN eller UNREACHABLE og service-objekter som har WARNING eller CRITICAL i statusvisningen, ble to løsninger vurdert. 

Den ene metoden var å bruke et severity-tall som Icinga kalkulerer basert på hvor mange child-hosts og child-servicer som hører til et gitt host-objekt som er nede. Dette vises som “network outages” i Icinga Classic Web der hver host får et “severity”-tall. Det eksisterte ikke noen dokumentasjon om dette kunne hentes ut via API-et eller hvordan “severity” kalkuleres. 

Utrekningen skjer i outages.cgi, som ble funnet etter å lese gjennom HTML-koden og lese kildekoden for outages.c /ref https://github.com/dnsmichi/icinga/blob/master/cgi/outages.c : 
Child-servicer blir delt på et forhåndsdefinert tall (service\_severity\_divisor) som brukes for å angi hvor kritisk det er i forhold til child-hosts.

\begin{lstlisting}
temp_hostoutage->severity = (temp_hostoutage->affected_child_hosts + (temp_hostoutage->affected_child_services / service_severity_divisor));
\end{lstlisting}

Det kalkulerte tallet baseres på at hosten som er nede er parent til en eller flere andre hosts. Dette er ikke alltid tilfellet, og metoden vil da ignorere alle host-objekter som ikke er en parent. En annen svakhet er at antall services vil bli kalkulert mot en statisk variabel, som ikke nødvendigvis gjengir viktigheten.

Eksempel:

service\_severity\_divisor = 4 

En host med en child-host som kjører to servicer som er viktige

Severity = 1 + (2/4) = 1.5

En host med to child-hosts som kjører to servicer hver, men er ikke like viktige som nr. 1

Severity = 1 + (4/4) = 2

Metoden er ikke anvendelig for prioriteringen, da det skal kunne settes på hvilken som helst service eller host, og den gjengir ikke viktigheten godt nok.     

Den andre metoden gruppen kom frem til var å sette en egendefinert variabel “\_PRIORITY” på host- og service-objekter, og å hente ut variabelen via API-et til Icinga-web.

Metoden med egendefinert variabel ble valgt, fordi denne kan anvendes på alle servicer og hosts, og gir et bedre prioriteringsgrunnlag enn severity som vurderer antall childs, noe ikke alle hosts nødvendigvis har. En kan heller ikke prioritere en service med metode 1.

Implementasjonen av metode to blir gjort ved å spørre API-et for hver host eller service som er hentet ut fra det første kallet (ref x.x). Har hosten eller servicen variabelen \_PRIORITY definert, vil denne lagres, ellers blir det satt 0 som prioritetstall.

Selve sorteringen av hosts og servicer blir gjort av PHP-funksjonen usort() med to egenskrevne sammenligningsfunksjoner. http://php.net/manual/en/function.usort.php. Grunnen til dette er at arrayet er flerdimensjonalt, så det må sorteres på verdien til en spesifikk nøkkel. Det skal også sorteres innenfor state-ene DOWN og UNREACHABLE, og CRITICAL og WARNING. DOWN skal gå foran UNREACHABLE for host-objekter, og CRITICAL foran WARNING for service-objekter, deretter sorteres det etter prioriteringsvariabelen.




















































	


.
